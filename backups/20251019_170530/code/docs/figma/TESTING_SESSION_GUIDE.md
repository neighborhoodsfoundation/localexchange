# LocalEx User Testing - Session Guide
*Complete Guide for Conducting User Testing Sessions*

**Version**: 1.0  
**Date**: January 19, 2025  
**Purpose**: Detailed guide for conducting user testing sessions  
**Duration**: 60 minutes per session

---

## 🎯 **Session Overview**

### **Session Objectives**
```
Primary Goals:
1. Validate core user flows and navigation
2. Identify usability issues and pain points
3. Gather feedback on design and functionality
4. Test user comprehension of key features
5. Evaluate overall user experience satisfaction

Success Criteria:
- All 5 scenarios completed
- Clear feedback on each scenario
- Honest opinions and suggestions
- Comfortable and engaging experience
- Actionable insights gathered
```

### **Session Structure**
```
Total Duration: 60 minutes
Pre-Session: 10 minutes
Main Testing: 45 minutes
Post-Session: 5 minutes

Breakdown:
- Introduction and setup: 10 minutes
- Scenario 1 (Onboarding): 9 minutes
- Scenario 2 (Item Listing): 9 minutes
- Scenario 3 (Search): 9 minutes
- Scenario 4 (Negotiation): 9 minutes
- Scenario 5 (Payment): 9 minutes
- Final feedback: 5 minutes
```

---

## 📋 **Pre-Session Setup (10 minutes)**

### **Welcome and Introduction**
```
Script:
"Welcome! Thank you so much for taking the time to help us test our new local trading app called LocalEx. My name is [Your Name] and I'll be guiding you through today's session.

Today we're testing a prototype of our app to see how easy it is to use and identify any areas for improvement. There are no right or wrong answers - we're testing the app, not you. Your honest feedback is exactly what we need to make this app better.

The session will take about 60 minutes. I'll ask you to complete some tasks while thinking out loud about what you're doing and why. Please don't worry about hurting our feelings - honest feedback is exactly what we need.

I'll be taking notes and recording the session for analysis. Everything you say will be kept confidential and used only to improve the app.

Do you have any questions before we begin?"

Key Points:
- Emphasize that we're testing the app, not the user
- Encourage honest feedback
- Explain the think-aloud process
- Confirm recording permission
- Set expectations for duration
```

### **Consent and Setup**
```
Consent Form:
"Before we begin, I need you to sign this consent form. It explains that we'll be recording the session and how we'll use your feedback. Please take a moment to read it and let me know if you have any questions."

Setup Tasks:
1. Have participant sign consent form
2. Set up recording equipment
3. Load Figma prototype on testing device
4. Ensure comfortable seating and lighting
5. Provide water or refreshments
6. Confirm participant is ready to begin

Technical Setup:
- Figma prototype loaded and ready
- Screen recording software active
- Audio recording working
- Backup recording method ready
- Timer ready for task timing
```

### **Background Questions**
```
Quick Background Questions:
1. "Tell me a little about yourself - what do you do for work?"
2. "How often do you use your smartphone?"
3. "What online marketplaces have you used before?"
4. "What's your experience with buying and selling items online?"
5. "What do you like most about current online marketplaces?"
6. "What frustrates you about current online marketplaces?"

Purpose:
- Build rapport with participant
- Understand their experience level
- Set context for their feedback
- Make them comfortable sharing opinions
- Gather baseline expectations
```

---

## 🧪23 **Main Testing Scenarios (45 minutes)**

### **Scenario 1: First-Time User Onboarding (9 minutes)**

#### **Task Introduction**
```
Script:
"Now I'd like you to try our first scenario. Imagine you've heard about LocalEx and want to try it out. You're looking for a new app to buy and sell items locally.

Please go ahead and create an account and set up your profile. Remember to think out loud as you work, telling me what you're trying to do and any thoughts you have about the process.

Take your time - there's no rush. If you get stuck or confused, that's valuable information for us.

Ready to begin?"

Success Criteria:
- User can complete registration flow
- User understands the app's purpose
- User can navigate to main features
- User feels comfortable with the process
```

#### **Observation Points**
```
Key Things to Watch:
- Does the user understand what LocalEx does?
- Are there any confusing steps in registration?
- Does the profile setup feel overwhelming?
- Does the tutorial help or hinder?
- How long does it take to complete?
- What questions or concerns arise?

Data to Collect:
- Time to complete registration
- Number of errors or confusions
- User comments and reactions
- Areas of hesitation or uncertainty
- Positive feedback and praise
- Suggestions for improvement
```

#### **Post-Task Questions**
```
Questions to Ask:
1. "How did that feel? Was it easy or difficult?"
2. "What did you think of that process?"
3. "Was there anything confusing or unclear?"
4. "What would you expect to happen next?"
5. "Any suggestions for improvement?"

Follow-up Questions:
- "Did you understand what the app does?"
- "Was the registration process clear?"
- "Did the tutorial help you understand the app?"
- "How confident do you feel about using this app?"
```

### **Scenario 2: Item Listing Creation (9 minutes)**

#### **Task Introduction**
```
Script:
"Great! Now let's try our second scenario. Imagine you have a bicycle you want to sell. You've heard that LocalEx is good for local trading, so you want to list it for sale.

Please show me how you would list this bicycle for sale. Take your time and go through the entire process.

Remember to think out loud as you work, telling me what you're trying to do and any thoughts you have about the process.

Ready to begin?"

Success Criteria:
- User can find the listing creation flow
- User can upload photos successfully
- User can fill out item details
- User understands pricing and fees
- User completes the listing process
```

#### **Observation Points**
```
Key Things to Watch:
- Is the photo upload process intuitive?
- Are the form fields clear and helpful?
- Does the user understand the pricing?
- Are there any confusing steps?
- How long does it take to complete?
- What questions or concerns arise?

Data to Collect:
- Time to complete listing
- Number of errors or confusions
- User comments and reactions
- Areas of hesitation or uncertainty
- Positive feedback and praise
- Suggestions for improvement
```

#### **Post-Task Questions**
```
Questions to Ask:
1. "How did that feel? Was it easy or difficult?"
2. "What did you think of that process?"
3. "Was there anything confusing or unclear?"
4. "What would you expect to happen next?"
5. "Any suggestions for improvement?"

Follow-up Questions:
- "Was the photo upload process clear?"
- "Did you understand the pricing and fees?"
- "Were the form fields helpful?"
- "How confident do you feel about listing items?"
```

### **Scenario 3: Item Discovery & Search (9 minutes)**

#### **Task Introduction**
```
Script:
"Now let's try our third scenario. Imagine you're looking for a coffee table for your living room. You've heard that LocalEx has good local items, so you want to search for one.

Please show me how you would search for a coffee table. Try to find something you might be interested in.

Remember to think out loud as you work, telling me what you're trying to do and any thoughts you have about the process.

Ready to begin?"

Success Criteria:
- User can use search functionality effectively
- User can apply filters appropriately
- User can view item details
- User understands how to make an offer
- User can navigate search results
```

#### **Observation Points**
```
Key Things to Watch:
- Is the search function easy to find and use?
- Do the filters make sense?
- Can the user easily browse results?
- Is the item detail view helpful?
- How long does it take to complete?
- What questions or concerns arise?

Data to Collect:
- Time to complete search
- Number of errors or confusions
- User comments and reactions
- Areas of hesitation or uncertainty
- Positive feedback and praise
- Suggestions for improvement
```

#### **Post-Task Questions**
```
Questions to Ask:
1. "How did that feel? Was it easy or difficult?"
2. "What did you think of that process?"
3. "Was there anything confusing or unclear?"
4. "What would you expect to happen next?"
5. "Any suggestions for improvement?"

Follow-up Questions:
- "Was the search function easy to use?"
- "Did the filters help you find what you wanted?"
- "Was the item detail view helpful?"
- "How confident do you feel about finding items?"
```

### **Scenario 4: Trade Negotiation (9 minutes)**

#### **Task Introduction**
```
Script:
"Now let's try our fourth scenario. Imagine you found a coffee table you're interested in. You want to make an offer and negotiate with the seller.

Please show me how you would make an offer and what happens if the seller counters your offer.

Remember to think out loud as you work, telling me what you're trying to do and any thoughts you have about the process.

Ready to begin?"

Success Criteria:
- User can make an initial offer
- User can communicate with seller
- User understands the negotiation process
- User can accept/decline counter-offers
- User understands the payment process
```

#### **Observation Points**
```
Key Things to Watch:
- Is the offer creation process clear?
- Does the chat interface work well?
- Can the user understand the negotiation flow?
- Are the payment steps clear?
- How long does it take to complete?
- What questions or concerns arise?

Data to Collect:
- Time to complete negotiation
- Number of errors or confusions
- User comments and reactions
- Areas of hesitation or uncertainty
- Positive feedback and praise
- Suggestions for improvement
```

#### **Post-Task Questions**
```
Questions to Ask:
1. "How did that feel? Was it easy or difficult?"
2. "What did you think of that process?"
3. "Was there anything confusing or unclear?"
4. "What would you expect to happen next?"
5. "Any suggestions for improvement?"

Follow-up Questions:
- "Was the offer creation process clear?"
- "Did the chat interface work well?"
- "Could you understand the negotiation flow?"
- "How confident do you feel about negotiating?"
```

### **Scenario 5: Payment & Completion (9 minutes)**

#### **Task Introduction**
```
Script:
"Now let's try our final scenario. Imagine you've agreed on a price for the coffee table. You want to complete the purchase and meet up with the seller.

Please show me how you would complete the purchase and what happens next in the process.

Remember to think out loud as you work, telling me what you're trying to do and any thoughts you have about the process.

Ready to begin?"

Success Criteria:
- User understands payment process
- User understands escrow system
- User can complete the transaction
- User understands meetup coordination
- User can provide feedback
```

#### **Observation Points**
```
Key Things to Watch:
- Is the payment process clear and trustworthy?
- Does the escrow explanation make sense?
- Are the meeting coordination steps helpful?
- Is the feedback process easy to complete?
- How long does it take to complete?
- What questions or concerns arise?

Data to Collect:
- Time to complete payment
- Number of errors or confusions
- User comments and reactions
- Areas of hesitation or uncertainty
- Positive feedback and praise
- Suggestions for improvement
```

#### **Post-Task Questions**
```
Questions to Ask:
1. "How did that feel? Was it easy or difficult?"
2. "What did you think of that process?"
3. "Was there anything confusing or unclear?"
4. "What would you expect to happen next?"
5. "Any suggestions for improvement?"

Follow-up Questions:
- "Did you understand the payment process?"
- "Was the escrow explanation clear?"
- "Did the meeting coordination make sense?"
- "How confident do you feel about completing trades?"
```

---

## 📊 **Post-Session Feedback (5 minutes)**

### **Overall Experience Questions**
```
Script:
"Great! You've completed all the testing scenarios. Now I'd like to get your overall thoughts about the app.

Overall, how would you rate your experience?"

Questions to Ask:
1. "Overall, how would you rate your experience?" (1-5 scale)
2. "What did you like most about the app?"
3. "What did you like least?"
4. "What would you change or improve?"
5. "Would you use this app? Why or why not?"
6. "How does this compare to other apps you use?"
7. "What features would you use most?"
8. "What's missing that you'd expect?"
9. "Do you feel safe using this app?"
10. "Would you recommend this to friends?"
```

### **Trust and Safety Questions**
```
Specific Questions:
1. "Do you feel safe using this app?" (1-5 scale)
2. "Are the payment processes trustworthy?" (1-5 scale)
3. "Do you understand how disputes are handled?" (1-5 scale)
4. "Are the privacy protections clear?" (1-5 scale)
5. "Would you feel comfortable meeting someone from this app?" (1-5 scale)
6. "What would make you feel safer?"
7. "What concerns do you have about safety?"
8. "How does this compare to other apps for safety?"
```

### **Feature Preference Questions**
```
Specific Questions:
1. "What features would you use most?"
2. "What features are most important to you?"
3. "What features are missing that you'd expect?"
4. "What features would you never use?"
5. "How important is the chat feature?"
6. "How important is the photo feature?"
7. "How important is the search feature?"
8. "How important is the payment feature?"
```

### **Final Questions**
```
Closing Questions:
1. "Is there anything else you'd like to tell us?"
2. "Any final suggestions or comments?"
3. "Would you be interested in testing future versions?"
4. "Do you have any questions for us?"
5. "Thank you for your time and feedback!"
```

---

## 📝 **Data Collection**

### **During Session**
```
Real-time Data Collection:
- Screen recording (with permission)
- Audio recording for think-aloud
- Written notes on observations
- Time tracking for each task
- Error counting and categorization
- User quotes and reactions
- Areas of confusion or hesitation
- Positive feedback and praise
- Suggestions and improvements
```

### **Post-Session**
```
Immediate Data Collection:
- Overall experience rating
- Task completion rates
- Time measurements
- Error counts
- User satisfaction scores
- Feature preferences
- Trust and safety ratings
- Likelihood to use ratings
- Net Promoter Score (NPS)
```

### **Data Organization**
```
File Structure:
- Participant folder with ID
- Screen recording file
- Audio recording file
- Written notes file
- Feedback form
- Summary sheet
- Key quotes document
- Issue tracking list
```

---

## 🎯 **Quality Assurance**

### **Session Quality Checks**
```
Pre-Session Checks:
- Recording equipment working
- Figma prototype loaded
- Consent form signed
- Participant comfortable
- Environment ready

During Session Checks:
- All scenarios completed
- Recording quality good
- Notes comprehensive
- Timing accurate
- Participant engaged

Post-Session Checks:
- All data collected
- Feedback form complete
- Recording saved
- Notes organized
- Participant satisfied
```

### **Data Quality Checks**
```
Recording Quality:
- Clear screen recording
- Good audio quality
- Complete session captured
- Backup recording available
- Files properly saved

Note Quality:
- Comprehensive observations
- Clear and detailed notes
- User quotes captured
- Issues identified
- Suggestions recorded

Feedback Quality:
- All questions answered
- Honest feedback provided
- Suggestions captured
- Ratings completed
- Additional comments noted
```

---

## 📋 **Session Checklist**

### **Pre-Session Checklist**
```
Technical Setup:
□ Figma prototype loaded and ready
□ Screen recording software configured
□ Audio recording working
□ Backup recording method ready
□ Testing device prepared
□ Internet connection stable

Materials Ready:
□ Consent form printed
□ Testing script prepared
□ Feedback forms ready
□ Timer ready
□ Note-taking materials ready
□ Gift card prepared

Participant Preparation:
□ Participant confirmed and on time
□ Consent form signed
□ Background questions completed
□ Testing device familiarized
□ Questions answered
□ Ready to begin
```

### **During Session Checklist**
```
Task Execution:
□ Task clearly explained
□ Participant thinking out loud
□ Time tracking for each task
□ Error counting and noting
□ Observations documented
□ Follow-up questions asked

Data Collection:
□ Screen recording active
□ Audio recording clear
□ Notes taken on key issues
□ Participant quotes captured
□ Task completion status noted
□ Time measurements recorded
```

### **Post-Session Checklist**
```
Data Collection:
□ Feedback form completed
□ Follow-up questions asked
□ Gift card provided
□ Contact information updated
□ Thank you and next steps explained

Session Wrap-up:
□ Recording stopped and saved
□ Notes organized and filed
□ Key insights summarized
□ Next participant prepared
□ Testing materials updated
```

---

**🎯 This comprehensive session guide ensures consistent, high-quality user testing sessions that gather valuable insights for LocalEx development!**
